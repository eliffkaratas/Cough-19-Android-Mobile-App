{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proje.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkAUTgVWrlkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e2383d-bb9b-41f6-dac3-86e73cacc76f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WAUSWYlJt2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cb0785-0c83-45a3-dfcf-341163195113"
      },
      "source": [
        "# feature extractoring and preprocessing data\n",
        "import librosa,librosa.display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import csv\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, scale\n",
        "\n",
        "#Keras\n",
        "import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras.regularizers import l1\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn import metrics\n",
        "import pylab\n",
        "plt.switch_backend('agg')\n",
        "import itertools\n",
        "import scipy as sp\n",
        "from scipy import signal\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from glob import glob\n",
        "import urllib\n",
        "\n",
        "\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "\n",
        "\n",
        "#Loading CSV file\n",
        "train_csv = pd.read_csv(\"/content/drive/MyDrive/CovidDataNew/cough_trial_extended.csv\")\n",
        "dataset = \"/content/drive/MyDrive/CovidDataNew/data_new_extended.csv\"\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/CovidDataNew/data_new_extended.csv\")\n",
        "\n",
        "data = data.drop(['filename'],axis=1)\n",
        "\n",
        "genre_list = data.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(genre_list)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# plot model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128)   \n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
        "\n",
        "print('test_acc: ',test_acc)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "#print(predictions[0].shape)\n",
        "#print(np.sum(predictions[0]))\n",
        "#print(predictions[:14])\n",
        "#print(y_test[:14])\n",
        "\n",
        "def one_record_predict():\n",
        "\n",
        "    xxx_csv = pd.read_csv(\"/content/drive/MyDrive/new.csv\")\n",
        "\n",
        "    cmap = plt.get_cmap('inferno')\n",
        "    tot_rows = xxx_csv.shape[0]\n",
        "    for i in range(tot_rows):\n",
        "        source = xxx_csv['file_properties'][i]\n",
        "        filename = '/content/drive/MyDrive/trial/'+source\n",
        "        y,sr = librosa.load(filename, mono=True, duration=5)\n",
        "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
        "        plt.axis('off');\n",
        "        plt.savefig(f'./{source[:-3].replace(\".\", \"\")}.png')\n",
        "        plt.clf()\n",
        "\n",
        "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header = header.split()\n",
        "\n",
        "\n",
        "    file = open('xxx_sample_extended', 'w')\n",
        "    with file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(header)\n",
        "    for i in range(tot_rows):\n",
        "            source = xxx_csv['file_properties'][i]\n",
        "            file_name = '/content/drive/MyDrive/trial/'+source\n",
        "            y,sr = librosa.load(file_name, mono=True, duration=5)\n",
        "            chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "            rmse = librosa.feature.rms(y=y)\n",
        "            spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "            zcr = librosa.feature.zero_crossing_rate(y)\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "            to_append = f'{source[:-3].replace(\".\", \"\")} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "            for e in mfcc:\n",
        "                to_append += f' {np.mean(e)}'\n",
        "          \n",
        "            file = open('xxx_sample_extended', 'a')\n",
        "            with file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow(to_append.split())\n",
        "\n",
        "\n",
        "    okuma = pd.read_csv(\"/content/xxx_sample_extended\")\n",
        "\n",
        "    okuma = okuma.drop(['filename'],axis=1)\n",
        "\n",
        "    okuma = okuma.to_numpy()\n",
        "\n",
        "    index = 0\n",
        "    for i in data.iloc[:, :-1].mean(axis=0):\n",
        "        okuma[0,index] = okuma[0,index] - i\n",
        "        index = index + 1\n",
        "\n",
        "    index = 0\n",
        "    for i in data.iloc[:, :-1].std(axis=0):\n",
        "        okuma[0,index] = okuma[0,index] / i\n",
        "        index = index + 1\n",
        "\n",
        "    result = model.predict(okuma)\n",
        "    \n",
        "    if result[0,0] == 1:\n",
        "        print(\"%100 covid\")\n",
        "    elif result[0,1] == 1:\n",
        "        print(\"%100 not covid\")\n",
        "    else:\n",
        "        print(\"% {:.2f} covid olma ihtimaliniz var\".format(result[0,0] * 100))\n",
        "     \n",
        "    print(result)\n",
        "one_record_predict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               13824     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 186,976\n",
            "Trainable params: 186,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 15s 15s/step - loss: 0.7291 - accuracy: 0.3701\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6416 - accuracy: 0.8661\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5872 - accuracy: 0.8661\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5210 - accuracy: 0.8661\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4528 - accuracy: 0.8661\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3877 - accuracy: 0.8661\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8661\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2772 - accuracy: 0.8661\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2300 - accuracy: 0.8661\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1851 - accuracy: 0.8898\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1442 - accuracy: 0.9685\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1119 - accuracy: 0.9764\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0914 - accuracy: 0.9764\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0757 - accuracy: 0.9764\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0606 - accuracy: 0.9843\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0445 - accuracy: 0.9843\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.8052e-04 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.5342e-04 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.9424e-04 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8052e-04 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.9904e-04 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.3933e-04 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9443e-04 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6035e-04 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3410e-04 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1372e-04 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7520e-05 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4577e-05 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4109e-05 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.5493e-05 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8331e-05 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.2346e-05 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.7297e-05 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.2999e-05 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.9340e-05 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.6196e-05 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.3472e-05 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.1102e-05 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.9029e-05 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7221e-05 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5622e-05 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4204e-05 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2958e-05 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1838e-05 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0843e-05 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9947e-05 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.9146e-05 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.8420e-05 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.7761e-05 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.7169e-05 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6626e-05 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6135e-05 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5687e-05 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.5269e-05 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4889e-05 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4541e-05 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4220e-05 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.3919e-05 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.3643e-05 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.3385e-05 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3147e-05 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2922e-05 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2712e-05 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2515e-05 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2327e-05 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.2155e-05 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.1985e-05 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1831e-05 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.1683e-05 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1543e-05 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.1409e-05 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1279e-05 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1159e-05 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1040e-05 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0927e-05 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0822e-05 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0717e-05 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0617e-05 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0517e-05 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0425e-05 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0329e-05 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0243e-05 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0157e-05 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0073e-05 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.9959e-06 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.9105e-06 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.8382e-06 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.7603e-06 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6881e-06 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.6186e-06 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.5454e-06 - accuracy: 1.0000\n",
            "2/2 [==============================] - 1s 6ms/step - loss: 0.3013 - accuracy: 0.9535\n",
            "test_acc:  0.9534883499145508\n",
            "% 0.39 covid olma ihtimaliniz var\n",
            "[[0.00390472 0.99609524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRdGizKeTCA8"
      },
      "source": [
        "# Yeni Bölüm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li4cMOMVwRKM"
      },
      "source": [
        "PREDİCTİONLARIN SAĞ TARAFI NOT COVİD - SOL TARAFI COVİD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4We0EUhyGbTn",
        "outputId": "882c6fb6-9233-4705-cc3c-3ef528ff3661"
      },
      "source": [
        "pip install pycryptodome"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (3.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shs74ubdG5xX",
        "outputId": "416a911e-4985-4745-fd95-77aee3ee7425"
      },
      "source": [
        "pip install pyrebase"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyrebase in /usr/local/lib/python3.7/dist-packages (3.0.27)\n",
            "Requirement already satisfied: python-jwt==2.0.1 in /usr/local/lib/python3.7/dist-packages (from pyrebase) (2.0.1)\n",
            "Requirement already satisfied: gcloud==0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyrebase) (0.17.0)\n",
            "Requirement already satisfied: pycryptodome==3.4.3 in /usr/local/lib/python3.7/dist-packages (from pyrebase) (3.4.3)\n",
            "Requirement already satisfied: requests-toolbelt==0.7.0 in /usr/local/lib/python3.7/dist-packages (from pyrebase) (0.7.0)\n",
            "Requirement already satisfied: oauth2client==3.0.0 in /usr/local/lib/python3.7/dist-packages (from pyrebase) (3.0.0)\n",
            "Requirement already satisfied: requests==2.11.1 in /usr/local/lib/python3.7/dist-packages (from pyrebase) (2.11.1)\n",
            "Requirement already satisfied: jws>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from python-jwt==2.0.1->pyrebase) (0.1.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (0.17.4)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (1.53.0)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gcloud==0.17.0->pyrebase) (1.15.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client==3.0.0->pyrebase) (0.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.0.0.b2.post1,>=3.0.0b2->gcloud==0.17.0->pyrebase) (57.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGnfq8R4HLBm"
      },
      "source": [
        "import pyrebase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrvWywKBNmk4"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFVMQU1nJJGm"
      },
      "source": [
        "filelist = [ f for f in os.listdir(\"/\") if f.endswith(\".wav\")]\n",
        "for f in filelist:\n",
        "  os.remove(os.path.join(\"/\",f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JEWG99KHOUt"
      },
      "source": [
        "config = {\n",
        "    \"apiKey\": \"AIzaSyCMMoRwkj8uOXmzq1XGEuvx153UQ9_Xb9Y\",\n",
        "    \"authDomain\": \"covid19-4f0ea.firebaseapp.com\",\n",
        "    \"databaseURL\": \"https://covid19-4f0ea.firebaseio.com\",\n",
        "    \"projectId\": \"covid19-4f0ea\",\n",
        "    \"storageBucket\": \"covid19-4f0ea.appspot.com\",\n",
        "    \"serviceAccount\": \"/content/sample_data/serviceAccountKey.json\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjuHzPzQIQ4m"
      },
      "source": [
        "firebase_storage = pyrebase.initialize_app(config)\n",
        "storage = firebase_storage.storage()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcjAOjl9JHvH",
        "outputId": "19c4eaa8-b4dd-4b4a-d5a2-e3fd08c074da"
      },
      "source": [
        "all_files = storage.list_files()\n",
        "for file in all_files:\n",
        "  print(file.name)\n",
        "  path = file.name\n",
        "  print(path)\n",
        "  print(\"USER ID: ------>\")\n",
        "  id = path[0:28]\n",
        "  print(id)\n",
        "\n",
        "  print(\"AUDIO FILE: ------>\")\n",
        "  audio_file = path[35:]\n",
        "  print(audio_file)\n",
        "  break\n",
        "\n",
        "file.download_to_filename(audio_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNVnabSkfAdbNk7XoOVbf0UBy7B2/Audio/8257e484-e3bb-45e1-8326-e37e823fea7a.wav\n",
            "UNVnabSkfAdbNk7XoOVbf0UBy7B2/Audio/8257e484-e3bb-45e1-8326-e37e823fea7a.wav\n",
            "USER ID: ------>\n",
            "UNVnabSkfAdbNk7XoOVbf0UBy7B2\n",
            "AUDIO FILE: ------>\n",
            "8257e484-e3bb-45e1-8326-e37e823fea7a.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJpZJtSZn0bk"
      },
      "source": [
        "import csv\n",
        "# exporting a string variable into the csv file\n",
        "input_variable = [\n",
        "    ['file_properties'],\n",
        "    [audio_file]\n",
        "]\n",
        "  \n",
        "# Example.csv gets created in the current working directory\n",
        "with open ('Example.csv','w',newline = '') as csvfile:\n",
        "    my_writer = csv.writer(csvfile, delimiter = ' ')\n",
        "    my_writer.writerows(input_variable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFEdbkculn_W"
      },
      "source": [
        "def one_record_predict():\n",
        "\n",
        "    xxx_csv = pd.read_csv(\"/content/Example.csv\")\n",
        "\n",
        "    cmap = plt.get_cmap('inferno')\n",
        "    tot_rows = xxx_csv.shape[0]\n",
        "    for i in range(tot_rows):\n",
        "        source = xxx_csv['file_properties'][i]\n",
        "        filename = '/content/'+source\n",
        "        y,sr = librosa.load(filename, mono=True, duration=5)\n",
        "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
        "        plt.axis('off');\n",
        "        plt.savefig(f'./{source[:-3].replace(\".\", \"\")}.png')\n",
        "        plt.clf()\n",
        "\n",
        "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header = header.split()\n",
        "\n",
        "\n",
        "    file = open('xxx_sample_extended', 'w')\n",
        "    with file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(header)\n",
        "    for i in range(tot_rows):\n",
        "            source = xxx_csv['file_properties'][i]\n",
        "            file_name = '/content/'+source\n",
        "            y,sr = librosa.load(file_name, mono=True, duration=5)\n",
        "            chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "            rmse = librosa.feature.rms(y=y)\n",
        "            spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "            zcr = librosa.feature.zero_crossing_rate(y)\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "            to_append = f'{source[:-3].replace(\".\", \"\")} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "            for e in mfcc:\n",
        "                to_append += f' {np.mean(e)}'\n",
        "          \n",
        "            file = open('xxx_sample_extended', 'a')\n",
        "            with file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow(to_append.split())\n",
        "\n",
        "\n",
        "    read = pd.read_csv(\"/content/xxx_sample_extended\")\n",
        "\n",
        "    read = read.drop(['filename'],axis=1)\n",
        "\n",
        "    read = read.to_numpy()\n",
        "\n",
        "    index = 0\n",
        "    for i in data.iloc[:, :-1].mean(axis=0):\n",
        "        read[0,index] = read[0,index] - i\n",
        "        index = index + 1\n",
        "\n",
        "    index = 0\n",
        "    for i in data.iloc[:, :-1].std(axis=0):\n",
        "        read[0,index] = read[0,index] / i\n",
        "        index = index + 1\n",
        "\n",
        "    result = model.predict(read)\n",
        "    print(result)\n",
        "    \n",
        "    if result[0,0] == 1:\n",
        "        app_result = 100;\n",
        "    elif result[0,1] == 1:\n",
        "        app_result = 0;\n",
        "    else:\n",
        "        print(\"% {:.2f} covid olma ihtimaliniz var\".format(result[0,0] * 100))\n",
        "        app_result = format(result[0,0] * 100);\n",
        "    return app_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "5QniDIluzzty",
        "outputId": "b78fba46-f905-4c5e-ce67-e1b8887cd24b"
      },
      "source": [
        "print(one_record_predict());"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py:7592: RuntimeWarning: divide by zero encountered in log10\n",
            "  Z = 10. * np.log10(spec)\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[9.392282e-13 1.000000e+00]]\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "h48MjMCu1J4l",
        "outputId": "424468af-43ae-4590-93f5-dc681c575f8d"
      },
      "source": [
        "db = firebase_storage.database()\n",
        "data = {\"Profiles/\"+id:{\"Accuracy\":one_record_predict()}}\n",
        "db.update(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py:7592: RuntimeWarning: divide by zero encountered in log10\n",
            "  Z = 10. * np.log10(spec)\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[9.392282e-13 1.000000e+00]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Profiles': {'UNVnabSkfAdbNk7XoOVbf0UBy7B2': {'Accuracy': 0}}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}